# ğŸ–¼ï¸â€¯Multimodal Cultural Safety: Evaluation Frameworks & Alignment Strategies  

<div align="center">
  <b>
    Haoyiâ€¯Qiu<sup>1</sup>, Kungâ€‘Hsiangâ€¯Huang<sup>2</sup>, Ruichenâ€¯Zheng<sup>1</sup>, Jiaoâ€¯Sun<sup>3</sup>, Nanyunâ€¯Peng<sup>1</sup>
  </b>
  <br>
  <sup>1</sup>UCLA, <sup>2</sup>Salesforceâ€¯AIâ€¯Research, <sup>3</sup>Googleâ€¯DeepMind
  <br><br>
  <a href="#"><img src="https://img.shields.io/badge/Paper-arXiv-orange"></a>
</div>


## Contents
1. [CROSS Evaluation Benchmark](#cross-evaluation-benchmark)
2. [CROSSâ€‘Eval Metrics](#crossâ€‘eval-metrics)
3. [Quickâ€‘Start](#quickâ€‘start-openai-models)
4. [Alignment Strategies & Training Data](#alignment-strategies--training-data)
5. [Citation](#citation)
6. [Disclaimer](#disclaimer)


## ğŸ§© CROSS Evaluation Benchmark  

```
data/
â”œâ”€â”€ casa/
â”‚   â”œâ”€â”€ english.json
â”‚   â””â”€â”€ multilingual.json
â””â”€â”€ safeworld/
    â”œâ”€â”€ english.json
    â””â”€â”€ multilingual.json
```

Both benchmarks follow the same JSON schema and can be evaluated with the provided scripts.


## âš–ï¸ CROSSâ€‘Eval Metrics  

CROSSâ€‘Eval reports four dimensions of culturally safe reasoning: 

- **Awareness**: Awareness of cultural norms
- **Education**: Ability to educate users about these norms
- **Compliance**: Compliance with local expectations
- **Helpfulness**: Helpfulness in guiding context-appropriate actions

Metric implementations are in `code/evaluation_.py`.


## ğŸ”§ Quickâ€‘Start

We provide generation & evaluation pipelines for GPTâ€‘4o and compatible OpenAI visionâ€‘language models.

```bash
# ğŸ”¹ Direct responses
bash scripts/run.sh

# ğŸ”¹ Responses with explicit reasoning
bash scripts/run_reasoning.sh
```

For **nonâ€‘OpenAI models** (e.g., InternVLâ€¯2.5, Qwenâ€¯VL, Llamaâ€‘4, Gemini), adapt the inference wrapper of your preferred framework (e.g., vllm) to match the input/output format used in our scripts.


## ğŸ§¨ Alignment Strategies & Training Data  

We release **Supervised Fine-tuning** (SFT) and **Direct Preference Optimization** (DPO) datasets tailored to GPTâ€‘4o:

```
data/
â”œâ”€â”€ cvqa_sft/        # vision QA
â”œâ”€â”€ safety_sft/      # textâ€‘only safety refinement
â””â”€â”€ safety_dpo/      # paired safe / unsafe responses for DPO
```

| Folder            | Positive examples | Negative / unsafe examples |
|-------------------|-------------------|----------------------------|
| `cvqa_sft`      | âœ”ï¸                | â€”                          |
| `safety_sft`    | âœ”ï¸                | â€”                          |
| `safety_dpo`    | âœ”ï¸                | âœ”ï¸ (unsafe)                |

Training scripts for GPTâ€‘4o are in `code/gpt4o_tuning.ipynb`.  
To fineâ€‘tune **other models**, reuse the JSONL data and update with your chosen framework (e.g., vllm).


## Citation  

If you use CROSS, CROSSâ€‘Eval, or our alignment data, please cite:

```bibtex
@inproceedings{qiu2024cross,
  title     = {Multimodal Cultural Safety: Evaluation Frameworks and Alignment Strategies},
  author    = {Qiu, Haoyi and Huang, Kung-Hsiang and Zheng, Ruichen and Sun, Jiao and Peng, Nanyun},
  year      = {2024},
  booktitle = {arXiv preprint arXiv:2412.06483}
}
```


## âš ï¸ Disclaimer  

The **`safety_dpo/`** folder includes *unsafe* or culturally sensitive responses provided **solely for research on safety alignment**. Handle these files with care. Do **not** redistribute or deploy them in production systems.
